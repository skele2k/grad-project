{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sector_id</th>\n",
       "      <th># of blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.652817</td>\n",
       "      <td>7487488</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652824</td>\n",
       "      <td>7489536</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.652830</td>\n",
       "      <td>7491584</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.652836</td>\n",
       "      <td>7493632</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.652842</td>\n",
       "      <td>7495680</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  sector_id  # of blocks\n",
       "0   1.652817    7487488         2048\n",
       "1   1.652824    7489536         2048\n",
       "2   1.652830    7491584         2048\n",
       "3   1.652836    7493632         2048\n",
       "4   1.652842    7495680         2048"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = pd.read_csv('../../data/trainData.csv', header=None)\n",
    "# AATI = Average Access Time Interval\n",
    "trainingData.columns = [\"timestamp\", \"sector_id\", \"# of blocks\"]\n",
    "trainingData.head()\n",
    "\n",
    "# trainingData.Frequency.hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp  sector_id  # of blocks\n",
      "0   0.000000     303567            7\n",
      "1   0.000000      55590            6\n",
      "2   0.026214     303574            7\n",
      "3   0.026214     240840            6\n",
      "4   0.117964     303581            7\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv(\"../../data/testData.csv\", header=None)\n",
    "testData.columns = [\"timestamp\", \"sector_id\", \"# of blocks\"]\n",
    "testData.head()\n",
    "\n",
    "print(testData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sector_id  frequency      AATI  # of blocks  hot/cold\n",
      "0     753921      90736  0.459198       544416         1\n",
      "1     240840      48735  0.886414       292465         1\n",
      "2     836706      31787  1.296780       195293         1\n",
      "3     837306      31704  1.299350       192217         1\n",
      "4     700132      31288  1.156710       247313         1\n"
     ]
    }
   ],
   "source": [
    "testDataLabel = pd.read_csv(\"../../data/lableing/testDataLabeled.csv\", header=None)\n",
    "testDataLabel.columns = [\"sector_id\", \"frequency\", \"AATI\", \"# of blocks\",\"hot/cold\"]\n",
    "print(testDataLabel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sector_id  frequency     AATI  # of blocks  hot/cold\n",
      "0       8488        966  36.0808         7728         1\n",
      "1     205888        948  36.7295         7584         1\n",
      "2     206064        948  36.7666         7584         1\n",
      "3      74328        947  36.7683         7576         1\n",
      "4      74408        945  36.8834         7560         1\n"
     ]
    }
   ],
   "source": [
    "trainDataLabel = pd.read_csv(\"../../data/lableing/trainDataLabeled.csv\", header=None)\n",
    "trainDataLabel.columns = [\"sector_id\", \"frequency\", \"AATI\", \"# of blocks\",\"hot/cold\"]\n",
    "print(trainDataLabel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDataLabel size: 1586700\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "trainLabelSize = trainDataLabel[\"sector_id\"].size\n",
    "print(\"trainDataLabel size:\", trainLabelSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sector_id        int64\n",
       "frequency        int64\n",
       "AATI           float64\n",
       "# of blocks      int64\n",
       "hot/cold         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLabel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp      float64\n",
       "sector_id        int64\n",
       "# of blocks      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingYLabelMap = {}\n",
    "\n",
    "for i in range(trainLabelSize):\n",
    "    trainingYLabelMap[trainDataLabel[\"sector_id\"][i]] = trainDataLabel[\"hot/cold\"][i]\n",
    "\n",
    "trainingData[\"hot/cold\"] = [trainingYLabelMap[sectorId] if sectorId in trainingYLabelMap else np.nan for sectorId in trainingData[\"sector_id\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabelSize = testDataLabel[\"sector_id\"].size\n",
    "testYLabelMap = {}\n",
    "\n",
    "for i in range(testLabelSize):\n",
    "    testYLabelMap[testDataLabel[\"sector_id\"][i]] = testDataLabel[\"hot/cold\"][i]\n",
    "\n",
    "testData[\"hot/cold\"] = [testYLabelMap[sectorId] if sectorId in testYLabelMap else np.nan for sectorId in testData[\"sector_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1354099\n",
       "1     232601\n",
       "Name: hot/cold, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLabel[\"hot/cold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6057980\n",
       "0    3628281\n",
       "Name: hot/cold, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[\"hot/cold\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2070048\n",
       "0    2029306\n",
       "Name: hot/cold, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData[\"hot/cold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing number of blocks\n",
    "trainBlocksMean = trainingData[\"# of blocks\"].mean()\n",
    "trainBlocksStd = trainingData[\"# of blocks\"].std()\n",
    "\n",
    "trainingData[\"# of blocks\"] = (trainingData[\"# of blocks\"] - trainBlocksMean) / trainBlocksStd\n",
    "\n",
    "testBlocksMean = testData[\"# of blocks\"].mean()\n",
    "testBlocksStd = testData[\"# of blocks\"].std()\n",
    "\n",
    "testData[\"# of blocks\"] = (testData[\"# of blocks\"] - testBlocksMean) / testBlocksStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try univariate LSTM first\n",
    "features = trainingData[[\"sector_id\"]].to_numpy().tolist()\n",
    "target = trainingData[[\"hot/cold\"]].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7487488], [7489536], [7491584], [7493632], [7495680]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 11:28:52.369503: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-26 11:28:53.016510: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-07-26 11:28:54.203531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-07-26 11:28:54.203747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-07-26 11:28:54.203760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WindowDataset element_spec=(DatasetSpec(TensorSpec(shape=(1,), dtype=tf.int32, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(1,), dtype=tf.int32, name=None), TensorShape([])))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: I basically concluded that large sector_ids are not possible to embed(preprocess).\n",
    "# However, I thought of a way to represent sector_ids in tensors and that is one hot encoding and deep neural networks (aka. Dense, Fully connected)\n",
    "# It could be wrong and I want more research on \n",
    "#   **representing numbers in one-hot encoding and RNN**\n",
    "#   **Is it possible to feed LSTM large numbers**\n",
    "# also checkout tf.data.Dataset.grouping_window() and tf.data.Dataset.window() functions \n",
    "# i think they can be used to generate windows. gl\n",
    "ds = tf.data.Dataset.from_tensor_slices((features, target))\n",
    "ds = ds.window(10, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([7487488], dtype=int32), array([7489536], dtype=int32), array([7491584], dtype=int32), array([7493632], dtype=int32), array([7495680], dtype=int32), array([7497728], dtype=int32), array([7499776], dtype=int32), array([7501824], dtype=int32), array([7503872], dtype=int32), array([7505920], dtype=int32)]\n",
      "[array([7489536], dtype=int32), array([7491584], dtype=int32), array([7493632], dtype=int32), array([7495680], dtype=int32), array([7497728], dtype=int32), array([7499776], dtype=int32), array([7501824], dtype=int32), array([7503872], dtype=int32), array([7505920], dtype=int32), array([7507968], dtype=int32)]\n",
      "[array([7491584], dtype=int32), array([7493632], dtype=int32), array([7495680], dtype=int32), array([7497728], dtype=int32), array([7499776], dtype=int32), array([7501824], dtype=int32), array([7503872], dtype=int32), array([7505920], dtype=int32), array([7507968], dtype=int32), array([7510016], dtype=int32)]\n",
      "[array([7493632], dtype=int32), array([7495680], dtype=int32), array([7497728], dtype=int32), array([7499776], dtype=int32), array([7501824], dtype=int32), array([7503872], dtype=int32), array([7505920], dtype=int32), array([7507968], dtype=int32), array([7510016], dtype=int32), array([7512064], dtype=int32)]\n",
      "[array([7495680], dtype=int32), array([7497728], dtype=int32), array([7499776], dtype=int32), array([7501824], dtype=int32), array([7503872], dtype=int32), array([7505920], dtype=int32), array([7507968], dtype=int32), array([7510016], dtype=int32), array([7512064], dtype=int32), array([7514112], dtype=int32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 11:55:02.932733: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    }
   ],
   "source": [
    "# Operations on window\n",
    "count = 0\n",
    "\n",
    "def to_numpy(ds):\n",
    "    return list(ds.as_numpy_iterator())\n",
    "\n",
    "for window in ds:\n",
    "    if count == 5:\n",
    "        break\n",
    "    print(to_numpy(window[0]))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxSectorNumber: 1000213824\n",
      "maxBlocks: 0.6759364762275851\n"
     ]
    }
   ],
   "source": [
    "maxSectorNumber = np.amax(trainingData[\"sector_id\"])\n",
    "maxBlocks = np.amax(trainingData[\"# of blocks\"])\n",
    "print(\"maxSectorNumber:\", maxSectorNumber)\n",
    "print(\"maxBlocks:\", maxBlocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1586700"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSectorSize = trainLabelSize\n",
    "trainLabelSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 11:39:35.713593: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 238.47GiB (rounded to 256054739200)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-07-26 11:39:35.713630: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2022-07-26 11:39:35.713641: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 8, Chunks in use: 8. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 57B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713648: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713655: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713661: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713667: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713672: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713694: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713701: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713707: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713712: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713718: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713723: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713728: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713734: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713739: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713745: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713751: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713756: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713762: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713773: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713779: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 3.30GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-26 11:39:35.713808: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 238.47GiB was 256.00MiB, Chunk State: \n",
      "2022-07-26 11:39:35.713823: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 3.30GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 256B | Requested Size: 16B | in_use: 1 | bin_num: -1\n",
      "2022-07-26 11:39:35.713829: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 3545563136\n",
      "2022-07-26 11:39:35.713839: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0000 of size 1280 next 1\n",
      "2022-07-26 11:39:35.713845: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0500 of size 256 next 2\n",
      "2022-07-26 11:39:35.713851: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0600 of size 256 next 3\n",
      "2022-07-26 11:39:35.713856: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0700 of size 256 next 4\n",
      "2022-07-26 11:39:35.713861: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0800 of size 256 next 5\n",
      "2022-07-26 11:39:35.713866: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0900 of size 256 next 6\n",
      "2022-07-26 11:39:35.713870: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0a00 of size 256 next 7\n",
      "2022-07-26 11:39:35.713875: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0b00 of size 256 next 8\n",
      "2022-07-26 11:39:35.713880: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 701ec0c00 of size 256 next 9\n",
      "2022-07-26 11:39:35.713886: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 701ec0d00 of size 3545559808 next 18446744073709551615\n",
      "2022-07-26 11:39:35.713891: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2022-07-26 11:39:35.713899: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 8 Chunks of size 256 totalling 2.0KiB\n",
      "2022-07-26 11:39:35.713905: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-07-26 11:39:35.713910: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 3.2KiB\n",
      "2022-07-26 11:39:35.713916: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 3545563136 memory_limit_: 3545563136 available bytes: 0 curr_region_allocation_bytes_: 7091126272\n",
      "2022-07-26 11:39:35.713927: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                      3545563136\n",
      "InUse:                            3328\n",
      "MaxInUse:                         3328\n",
      "NumAllocs:                           9\n",
      "MaxAllocSize:                     1280\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-07-26 11:39:35.713949: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *___________________________________________________________________________________________________\n",
      "2022-07-26 11:39:35.714006: W tensorflow/core/framework/op_kernel.cc:1777] OP_REQUIRES failed at stateless_random_ops_v2.cc:67 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1000213825,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1000213825,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000023?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000023?line=2'>3</a>\u001b[0m \u001b[39m# embedding the sector number from 0-1\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000023?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49madd(tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mEmbedding(input_dim\u001b[39m=\u001b[39;49mmaxSectorNumber\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m,output_dim\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000023?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m64\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/skele/Documents/PNU/grad/grad-project/src/model/rnn_model.ipynb#ch0000023?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.2\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[1;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[1;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[1;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   2106\u001b[0m     )\n\u001b[1;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1000213825,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# embedding the sector number from 0-1\n",
    "model.add(tf.keras.layers.Embedding(input_dim=maxSectorNumber+1,output_dim=64))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(64,activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer \n",
    "model.compile(optimizer='adam', loss='NLL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit\n",
    "model.fit(features, target, epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
